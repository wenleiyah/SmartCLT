{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1q0yB7kEhbYFEdfCRggBfFJv7pNjLq5Xk","timestamp":1688089508070}],"authorship_tag":"ABX9TyN+L7sp8ezQq5xKh1Pq/yKZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install opencv-python\n","!pip install pillow\n","!pip install ezdxf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hzs78vocUB9_","executionInfo":{"status":"ok","timestamp":1688091238992,"user_tz":-480,"elapsed":18200,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}},"outputId":"0dcb3b22-57e0-4dd3-c835-965a8fe72f31"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n","Requirement already satisfied: ezdxf in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from ezdxf) (3.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ezdxf) (4.6.3)\n"]}]},{"cell_type":"code","source":["#connect to google drive\n","import cv2\n","import numpy as np\n","from PIL import Image\n","import ezdxf\n","import os, sys\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAoFG95o_eYf","executionInfo":{"status":"ok","timestamp":1688091245321,"user_tz":-480,"elapsed":4665,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}},"outputId":"009627c7-6ec6-45ef-866d-37d69d1f528f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"id":"QjXUoadvTm32","executionInfo":{"status":"ok","timestamp":1688091249246,"user_tz":-480,"elapsed":694,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}}},"outputs":[],"source":["# Load the image and mask\n","id = \"01\"\n","inpath = '/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/'\n","inpath_ma = '/content/drive/Shareddrives/SmartCLT_DF2023/Scan2/GOOD_SCAN/'\n","outpath = '/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_0628/'\n","\n","input_img_name = inpath + 'Copy of'+ id +'_image.jpg'\n","input_mask_name = inpath_ma + id +'_mask.jpg'\n","input_solu_name = inpath + 'Copy of'+ id +'_solution.png'\n","\n","\n","img = cv2.imread(input_img_name)\n","mask = cv2.imread(input_mask_name,0)\n","solution = cv2.imread(input_solu_name, cv2.IMREAD_GRAYSCALE)"]},{"cell_type":"code","source":["# Increase brightness\n","bright_img = img + 50\n","\n","# Ensure pixel values are within valid range\n","bright_img = np.clip(bright_img, 0, 255)\n","\n","\n","# Increase blue and green channels to make the image yellower\n","yellow_img = bright_img.copy()\n","'''\n","yellow_img[:, :, 0] = np.clip(yellow_img[:, :, 0] + 30, 0, 255)  # Blue channel\n","yellow_img[:, :, 1] = np.clip(yellow_img[:, :, 1] + 30, 0, 255)  # Green channel\n","'''\n","# Optionally, decrease red channel if the wood appears too red\n","yellow_img[:, :, 2] = np.clip(yellow_img[:, :, 2] - 20, 0, 255)  # Red channel\n","\n","# Save the result\n","cv2.imwrite('bright_yellow_wood.jpg', yellow_img)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUkE0yPtEACo","executionInfo":{"status":"ok","timestamp":1688091254143,"user_tz":-480,"elapsed":900,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}},"outputId":"0f9027a7-ccd2-4010-a904-c89e846da504"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Convert the image from RGB to BGR format (this is what OpenCV uses)\n","img_bgr = cv2.cvtColor(yellow_img, cv2.COLOR_RGB2BGR)\n","\n","# Flip the solution vertically and horizontally\n","flipped_solu = cv2.flip(solution, -1)\n","\n","# Blur solution to enhance edge detection\n","flipped_solu = cv2.GaussianBlur(flipped_solu, (5, 5), 0)\n","\n","# Apply Canny edge detection\n","edges = cv2.Canny(flipped_solu,50,100)\n","\n","# Find contours in the binary image\n","contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","# Iterate over the contours and draw each one on the original image\n","buffer = 0.025\n","dy = -int(-3500/(1-2*buffer)*buffer)\n","dx = 0\n","\n","for contour in contours:\n","  if contours.index(contour) == 1:\n","    contour += np.array([dx, dy])\n","    contour = contour.reshape((-1, 1, 2))\n","    cv2.polylines(img_bgr, [contour], isClosed=True, color=(40, 160, 40), thickness=2)\n","\n","cv2.imwrite('output.png', img_bgr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXdbwIvdcItu","executionInfo":{"status":"ok","timestamp":1688091257544,"user_tz":-480,"elapsed":619,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}},"outputId":"2b65736a-8448-4e40-a318-051591ae111c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-2e7563816091>:22: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","  if contours.index(contour) == 1:\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Make sure your mask is a binary image (white and black only)\n","ret, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n","mask = cv2.resize(mask, (img_bgr.shape[1], img_bgr.shape[0]))\n","\n","# Erode the mask\n","kernel_size = 5  # You can adjust this value for more or less erosion\n","kernel = np.ones((kernel_size, kernel_size), np.uint8)\n","mask = cv2.erode(mask, kernel, iterations=1)\n","\n","# Blur the mask\n","mask = cv2.GaussianBlur(mask,(5,5),0)\n","\n","# Apply the mask to the image using bitwise 'and'\n","img_masked = cv2.bitwise_and(img_bgr, img_bgr, mask=mask)\n","\n","# Convert the image to RGB for PIL\n","img_masked = cv2.cvtColor(img_masked, cv2.COLOR_BGR2RGB)\n","\n","# Convert to a PIL Image\n","pil_img = Image.fromarray(img_bgr)\n","\n","# Create an alpha mask\n","alpha_mask = Image.fromarray(mask)\n","\n","# Convert black areas to transparent in the PIL image\n","pil_img.putalpha(alpha_mask)\n","\n","# Save the image\n","pil_img.save('trans.png')"],"metadata":{"id":"b771Rflwt1B_","executionInfo":{"status":"ok","timestamp":1688091263897,"user_tz":-480,"elapsed":2907,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rNk_reGSI6Ak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNPMTa8BI50I","executionInfo":{"status":"ok","timestamp":1688092814348,"user_tz":-480,"elapsed":3,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}},"outputId":"61f0f512-977b-4f0d-d885-bf2c0d117286"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["01 <class 'str'>\n","02 <class 'str'>\n","03 <class 'str'>\n","04 <class 'str'>\n","05 <class 'str'>\n","06 <class 'str'>\n","07 <class 'str'>\n","08 <class 'str'>\n","09 <class 'str'>\n","10 <class 'str'>\n","11 <class 'str'>\n","12 <class 'str'>\n","13 <class 'str'>\n","14 <class 'str'>\n","15 <class 'str'>\n","16 <class 'str'>\n","17 <class 'str'>\n","18 <class 'str'>\n","19 <class 'str'>\n","20 <class 'str'>\n","21 <class 'str'>\n","22 <class 'str'>\n","23 <class 'str'>\n","24 <class 'str'>\n","25 <class 'str'>\n","26 <class 'str'>\n","27 <class 'str'>\n","28 <class 'str'>\n","29 <class 'str'>\n","30 <class 'str'>\n","31 <class 'str'>\n","32 <class 'str'>\n","33 <class 'str'>\n","34 <class 'str'>\n"]}]},{"cell_type":"code","source":["def crop_and_overlay(id):\n","\n","  # 01_Load the image and mask\n","  inpath = '/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/'\n","  inpath_ma = '/content/drive/Shareddrives/SmartCLT_DF2023/Scan2/GOOD_SCAN/'\n","  outpath = '/content/drive/Shareddrives/SmartCLT_DF2023/Exhibition & Presentation/Imaging Process/image to dxf/'\n","\n","  input_img_name = inpath + 'Copy of '+ id +'_image.jpg'\n","  input_mask_name = inpath_ma + id +'_mask.jpg'\n","  input_solu_name = inpath + 'Copy of '+ id +'_solution.png'\n","\n","  out_name = outpath + id + '_overlay.png'\n","\n","  print(input_img_name)\n","\n","  img = cv2.imread(input_img_name)\n","  mask = cv2.imread(input_mask_name,0)\n","  solution = cv2.imread(input_solu_name, cv2.IMREAD_GRAYSCALE)\n","\n","\n","  #02_process image color\n","\n","\n","\n","  # Increase brightness\n","  bright_img = img + 50\n","\n","  # Ensure pixel values are within valid range\n","  bright_img = np.clip(bright_img, 0, 255)\n","\n","  # Increase blue and green channels to make the image yellower\n","  yellow_img = bright_img.copy()\n","\n","  # Optionally, decrease red channel if the wood appears too red\n","  yellow_img[:, :, 2] = np.clip(yellow_img[:, :, 2] - 20, 0, 255)  # Red channel\n","\n","\n","\n","  # 03_overlay cutting curve\n","  # Convert the image from RGB to BGR format (this is what OpenCV uses)\n","  img_bgr = cv2.cvtColor(yellow_img, cv2.COLOR_RGB2BGR)\n","\n","  # Flip the solution vertically and horizontally\n","  flipped_solu = cv2.flip(solution, 0)\n","\n","  # Blur solution to enhance edge detection\n","  flipped_solu = cv2.GaussianBlur(flipped_solu, (5, 5), 0)\n","\n","  # Apply Canny edge detection\n","  edges = cv2.Canny(flipped_solu,50,100)\n","\n","  # Find contours in the binary image\n","  contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","  # Iterate over the contours and draw each one on the original image\n","  buffer = 0.025\n","  dy = -int(-3500/(1-2*buffer)*buffer)\n","  dx = 0\n","\n","  for contour in contours:\n","    if contours.index(contour) == 1:\n","      contour += np.array([dx, dy])\n","      contour = contour.reshape((-1, 1, 2))\n","      cv2.polylines(img_bgr, [contour], isClosed=True, color=(40, 160, 40), thickness=2)\n","\n","\n","\n","\n","  #04_crop with mask\n","\n","  # Make sure your mask is a binary image (white and black only)\n","  img_bgr = img_bgr[int(3500/(1-2*buffer)*buffer):int(1-2*buffer*buffer+3500),0:606]\n","  ret, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n","  mask = cv2.resize(mask, (img_bgr.shape[1], img_bgr.shape[0]))\n","\n","  # Erode the mask\n","  kernel_size = 1  # You can adjust this value for more or less erosion\n","  kernel = np.ones((kernel_size, kernel_size), np.uint8)\n","  mask = cv2.erode(mask, kernel, iterations=1)\n","\n","  # Blur the mask\n","  mask = cv2.GaussianBlur(mask,(1,1),0)\n","\n","  # Apply the mask to the image using bitwise 'and'\n","  img_masked = cv2.bitwise_and(img_bgr, img_bgr, mask=mask)\n","\n","  # Convert the image to RGB for PIL\n","  img_masked = cv2.cvtColor(img_masked, cv2.COLOR_BGR2RGB)\n","\n","  # Convert to a PIL Image\n","  pil_img = Image.fromarray(img_bgr)\n","\n","  # Create an alpha mask\n","  alpha_mask = Image.fromarray(mask)\n","\n","  # Convert black areas to transparent in the PIL image\n","  pil_img.putalpha(alpha_mask)\n","\n","  # Save the image\n","  # pil_img.save(out_name)\n","  pil_img.save('30_overlay.png')\n","\n","\n"],"metadata":{"id":"kixDpzZDDkHO","executionInfo":{"status":"ok","timestamp":1688096572230,"user_tz":-480,"elapsed":395,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["for i in range(34):\n","    id=i+1\n","    if id<10:\n","      id='0'+str(id)\n","    else:\n","      id = str(id)\n","    crop_and_overlay(id)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":950},"id":"y8_HOXEbLJ5H","executionInfo":{"status":"error","timestamp":1688094222996,"user_tz":-480,"elapsed":74267,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}},"outputId":"0b231ab6-c279-4236-8196-ec7a8b9e5002"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 01_image.jpg\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-26-cf2c4e48dc98>:59: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","  if contours.index(contour) == 1:\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 02_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 03_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 04_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 05_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 06_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 07_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 08_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 09_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 10_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 11_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 12_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 13_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 14_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 15_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 16_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 17_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 18_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 19_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 20_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 21_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 22_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 23_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 24_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 25_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 26_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 27_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 28_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 29_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 30_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 31_image.jpg\n","/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 32_image.jpg\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-964b0a9cb5d2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcrop_and_overlay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-cf2c4e48dc98>\u001b[0m in \u001b[0;36mcrop_and_overlay\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mcontour\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0mcontour\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mcontour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"]}]},{"cell_type":"code","source":["crop_and_overlay('30')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w5wp2EZgLYNh","executionInfo":{"status":"ok","timestamp":1688096576674,"user_tz":-480,"elapsed":933,"user":{"displayName":"yuqing huang","userId":"05566664316902299600"}},"outputId":"94df56da-69ce-4003-c2b3-f3db447742e3"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/SmartCLT_DF2023/T_Algorithm/OUT-DXF/OUTPUT_FINAL/Copy of 30_image.jpg\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-405e9823c042>:61: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","  if contours.index(contour) == 1:\n"]}]}]}